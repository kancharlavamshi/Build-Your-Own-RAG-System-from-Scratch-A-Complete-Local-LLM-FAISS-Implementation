Build Your Own RAG System from Scratch
A Complete Local LLM + FAISS Implementation
<p align="center"> <img src="coverpage.jpg" alt="RAG System Architecture" width="100%"> </p>

Overview

This project demonstrates how to build a Retrieval-Augmented Generation (RAG) system from scratch using:
ğŸ¤– Local LLM (TinyLlama / Transformers)

ğŸ” FAISS Vector Search

ğŸ§  BGE Embeddings (GPU-Accelerated)

ğŸ“„ PDF Course Material

âš¡ Fully Local Inference (No APIs)

The system converts raw course notes into a context-aware AI study assistant.

## System Architecture

PDF Course Notes

        â†“
Text Extraction (PyPDF)

        â†“
Chunking (with overlap)

        â†“
Embedding Model (BGE)

        â†“
FAISS Vector Index

        â†“
User Question

        â†“
Query Embedding

        â†“
Top-K Relevant Chunks

        â†“
Local LLM (Transformers) 


## ğŸ›  Tech Stack

Python 3.12

PyTorch (CUDA)

HuggingFace Transformers

Sentence-Transformers (BGE-large)

FAISS (GPU)

PyPD
        â†“
Context-Aware Answer 

# ğŸ“Œ License
This repository contains only code.
Course materials should be downloaded separately according to their respective licenses.

# â­ Star This Repo
If this project helped you understand RAG from scratch, consider starring it.
